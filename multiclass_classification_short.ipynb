{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8UGyikmfTTzlkMEq1lmso",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwoong2/deeplearning/blob/main/multiclass_classification_short.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80eAFDF3r8uP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "LR = 1e-3\n",
        "EPOCH = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "new_model_train = True\n",
        "model_type = \"MLP\"\n",
        "dataset = \"MNIST\"\n",
        "save_model_path =f\"/content/drive/MyDrive/Colab Notebooks/results/{model_type}_{dataset}.pt\""
      ],
      "metadata": {
        "id": "qIXeJiJcswH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "train_DS = datasets.MNIST(root = '/content/drive/MyDrive/Colab Notebooks/data', train = True, download = True, transform = transform)\n",
        "test_DS = datasets.MNIST(root = '/content/drive/MyDrive/Colab Notebooks/data', train=False, download=True, transform=transform)\n",
        "train_DL = torch.utils.data.DataLoader(train_DS, batch_size = BATCH_SIZE, shuffle= True)\n",
        "test_DL = torch.utils.data.DataLoader(test_DS, batch_size = BATCH_SIZE, shuffle = True)"
      ],
      "metadata": {
        "id": "5MWFX4zUvuJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear = nn.Sequential(nn.Linear(28*28, 100),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(100, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "c6MfhaT2xuzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exec(f\"model = {model_type}().to(DEVICE)\")\n",
        "print(model)\n",
        "x_batch, _ = next(iter(train_DL))\n",
        "print(model(x_batch.to(DEVICE)).shape)"
      ],
      "metadata": {
        "id": "nVZzsgJny1v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train(model, train_DL, criterion, optimizer):\n",
        "\n",
        "    loss_history =[]\n",
        "    NoT = len(train_DL.dataset)\n",
        "\n",
        "    model.train() # train mode로 전환\n",
        "    for ep in range(EPOCH):\n",
        "        rloss = 0 # running loss\n",
        "        for x_batch, y_batch in train_DL:\n",
        "            x_batch = x_batch.to(DEVICE) # gpu에 올려주자.\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            # inference\n",
        "            y_hat = model(x_batch)\n",
        "            # loss\n",
        "            loss = criterion(y_hat, y_batch)\n",
        "            # update\n",
        "            optimizer.zero_grad() # gradient 누적을 막기 위한 초기화\n",
        "            loss.backward() # backpropagation\n",
        "            optimizer.step() # weight update\n",
        "            # loss accumulation\n",
        "            loss_b = loss.item() * x_batch.shape[0] # batch loss # BATCH_SIZE를 곱하면 마지막 18개도 32개를 곱하니까.. / 평균크로스엔트로피이므로\n",
        "            rloss += loss_b # running loss\n",
        "        # print loss\n",
        "        loss_e = rloss/NoT\n",
        "        loss_history += [loss_e]\n",
        "        print(f\"Epoch: {ep+1}, train loss: {round(loss_e,3)}\")\n",
        "        print(\"-\"*20)\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "def Test(model, test_DL):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        rcorrect = 0\n",
        "        for x_batch, y_batch in test_DL:\n",
        "            x_batch = x_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            # inference\n",
        "            y_hat = model(x_batch)\n",
        "            # accuracy accumulation\n",
        "            pred = y_hat.argmax(dim=1)\n",
        "            corrects_b = torch.sum(pred == y_batch).item()\n",
        "            rcorrect += corrects_b\n",
        "        accuracy_e = rcorrect/len(test_DL.dataset)*100\n",
        "    print(f\"Test accuracy: {rcorrect}/{len(test_DL.dataset)} ({round(accuracy_e,1)} %)\")\n",
        "\n",
        "def Test_plot(model, test_DL):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x_batch, y_batch = next(iter(test_DL))\n",
        "        x_batch = x_batch.to(DEVICE)\n",
        "        y_hat = model(x_batch)\n",
        "        pred = y_hat.argmax(dim=1)\n",
        "\n",
        "    x_batch = x_batch.to(\"cpu\")\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    for idx in range(6):\n",
        "        plt.subplot(2,3, idx+1, xticks=[], yticks=[])\n",
        "        plt.imshow(x_batch[idx].permute(1,2,0).squeeze(), cmap=\"gray\")\n",
        "        pred_class = test_DL.dataset.classes[pred[idx]]\n",
        "        true_class = test_DL.dataset.classes[y_batch[idx]]\n",
        "        plt.title(f\"{pred_class} ({true_class})\", color = \"g\" if pred_class==true_class else \"r\")\n",
        "\n",
        "def count_params(model):\n",
        "    num = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "    return num"
      ],
      "metadata": {
        "id": "6UD20e3T3C7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if new_model_train:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    loss_history = Train(model, train_DL, criterion, optimizer)\n",
        "\n",
        "    torch.save(model, save_model_path)\n",
        "\n",
        "    plt.plot(range(1,EPOCH+1),loss_history)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title(\"Train Loss\")\n",
        "    plt.grid()"
      ],
      "metadata": {
        "id": "cZoIXtkpzytS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = torch.load(save_model_path, map_location=DEVICE)"
      ],
      "metadata": {
        "id": "RWl4fUNG0hEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test(load_model, test_DL)\n",
        "print(count_params(load_model))"
      ],
      "metadata": {
        "id": "ZF5JfS_m2TlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_plot(load_model, test_DL)"
      ],
      "metadata": {
        "id": "1HlnJDt32d1D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}