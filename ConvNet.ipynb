{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1l9iVTHnqIr8hD-PKQoccjCspLnzSc6HD",
      "authorship_tag": "ABX9TyMYYpJTTXE8D8am2tNn7J9q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwoong2/deeplearning/blob/main/ConvNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab/module'\n",
        "!ls"
      ],
      "metadata": {
        "id": "m_IwR-hLRr9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import layers\n",
        "import optimizer"
      ],
      "metadata": {
        "id": "H9fTTXjBQqpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimpleConvNet"
      ],
      "metadata": {
        "id": "JBDXHpDGbpup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepConvNet:\n",
        "    # conv - relu - pool - affine - relu - affine - softmax\n",
        "\n",
        "    def __init__(self, input_dim = (1, 28, 28),\n",
        "                 conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride': 1},\n",
        "                 hidden_size = 100, output_size = 10, weight_init_std = 0.01): # 가중치 초기화 분포 설정 불완전.\n",
        "\n",
        "        filter_num = conv_param['filter_num']\n",
        "        filter_size = conv_param['filter_size']\n",
        "        filter_pad = conv_param['pad']\n",
        "        filter_stride = conv_param['stride']\n",
        "        input_size = input_dim[1]\n",
        "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1 # height, width를 따로 계산해야하지만 정사각이미지라서 하나만 계산.\n",
        "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
        "\n",
        "        # 가중치 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size) # 컨볼루션 레이어\n",
        "        self.params['b1'] = np.zeros('fiter_num')\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, output_size) # affine 레이어\n",
        "        self.params['b2'] = np.zeros(hidden_size)\n",
        "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size) # affine 레이어\n",
        "        self.params['b3'] = np.zeros(output_size)\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Conv1'] = layers.Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])\n",
        "        self.layers['Relu1'] = layers.Relu()\n",
        "        self.layers['Pool1'] = layers.Pooling(pool_h=2, pool_w=2, stride=2)\n",
        "        self.layers['Affine1'] = layers.Affine(self.params['W2'], self.params['b2'])\n",
        "        self.layers['Relu2'] = layers.Relu()\n",
        "        self.layers['Affine2'] = layers.Affine(self.params['W3'], self.params['b3'])\n",
        "\n",
        "        self.last_layer = self.SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values(): # last_layer는 제외 단순히 학습이 필요없고 단순히 스코어만 필요함.\n",
        "            x = layer.forward(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t): # x: 입력 데이터 t: 정답 레이블\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return self.last_layer.forward(y, t)\n",
        "\n",
        "    def accuracy(self, x, t, batch_size=100):\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1) # 정답레이블이 원-핫 인코딩 돼어 있을 경우\n",
        "\n",
        "        acc = 0.0\n",
        "\n",
        "        for i in range(int(x.shape[0] / batch_size)):\n",
        "            tx = x[i*batch_size:(i+1)*batch_size]\n",
        "            tt = t[i*batch_size:(i+1)*batch_size]\n",
        "            y = self.predict(tx)\n",
        "            y = np.argmax(y, axis=1)\n",
        "            acc += np.sum(y == tt) # 정답일 경우 더해준다.\n",
        "\n",
        "        return acc / x.shape[0]\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse() # 레이어 순서를 뒤집어 준다.\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 결과 저장\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def save_params(self, file_name=\"params.pkl\"):\n",
        "        params = {}\n",
        "        for key, val in self.params.items():\n",
        "            params[key] = val\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(params, f)\n",
        "\n",
        "    def load_params(self, file_name=\"params.pkl\"):\n",
        "        with open(file_name, 'rb') as f:\n",
        "            params = pickle.load(f)\n",
        "        for key, val in params.items():\n",
        "            self.params[key] = val\n",
        "\n",
        "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
        "            self.layers[key].W = self.params['W' + str(i+1)]\n",
        "            self.layers[key].b = self.params['b' + str(i+1)]"
      ],
      "metadata": {
        "id": "nn44Qi2AR_Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA"
      ],
      "metadata": {
        "id": "tzKVo11Sbzyw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hp84iXDnTeBs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}