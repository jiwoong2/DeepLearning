{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "R5c8FDJ8uRWY",
        "LWKX7iWF1JiK",
        "sHERwU8D-FBe"
      ],
      "authorship_tag": "ABX9TyOVd9tFl14iae5mldSkl6oZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwoong2/deeplearning/blob/main/%EA%B0%81%EC%B8%B5_%EC%88%9C%EC%A0%84%ED%8C%8C%2C_%EC%97%AD%EC%A0%84%ED%8C%8C_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nZj863xrfX0"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 필요한 함수들"
      ],
      "metadata": {
        "id": "5lksxa6OBhv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Affine층의 순전파와 역전파"
      ],
      "metadata": {
        "id": "R5c8FDJ8uRWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "범용적인 affine 층 구현"
      ],
      "metadata": {
        "id": "EtMPqWzjuYTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4차원 텐서를 염두해둔 코드이기 떄문에 다음 학기때완전히 이해가능\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W # 가중치 행렬\n",
        "        self.b = b # bias 벡터\n",
        "\n",
        "        # 입력된 data 초기화\n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 bias 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1) # 4차원 텐서를 행렬로 변환. -1을 입력하면 reshape 가능한 숫자를 알아서 대입한다.\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b # affine 변환. bias의 경우 배치처리를 할경우 행렬뎃섬에서 shape이 맞지 않는데 numpy에서 자동으로 벡터를 복사해 각 열에 더하게 된다.\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout): # dout:흘러들어온 미분\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0) # 행렬의 경우 axis 0: 행, 1: 열. 텐서의 경우 axis 0: 각 행렬, 1: 각 행렬의 행, 2: 각 행렬의 열\n",
        "\n",
        "        dx =dx.reshape(*self.original_x_shape) # 입력데이터\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "eAy-DJY9r0cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1,1]])\n",
        "\n",
        "W = np.array([[1,2,3],[4,5,6]])\n",
        "\n",
        "b = np.array([7,8,9])\n",
        "\n",
        "test = Affine(W,b)"
      ],
      "metadata": {
        "id": "_ARWvQCLyGdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 순전파 테스트\n",
        "test.forward(x)"
      ],
      "metadata": {
        "id": "MXrUjhR9yd8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 역전파 테스트\n",
        "print(test.backward(np.array([[2,1,-1]])))\n",
        "print(test.dW)\n",
        "print(test.db)"
      ],
      "metadata": {
        "id": "sRj5e7KMyiN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 배기처리 테스트\n",
        "y = np.array([[1,1],[2,3]])\n",
        "\n",
        "# 순전파 테스트\n",
        "print(test.forward(y))\n",
        "\n",
        "# 역전파 테스트\n",
        "print(test.backward(np.array([[2,1,-1],[1,1,1]])))\n",
        "print(test.dW)\n",
        "print(test.db)"
      ],
      "metadata": {
        "id": "J-An3fSz4hpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "간단한 affine층 구현"
      ],
      "metadata": {
        "id": "7YmYWwUAuck5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine_t:\n",
        "    def __init__(self, W, b): # W:가중치 matrix, b:bias\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x # x:data\n",
        "        out = np.dot(self.x, self.W) + self.b # affine 변환\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout): # dout:흘러들어온 미분\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0) # 덧셈노드의 역전파는 원래 흘러들어온 값이 그대로 통과하지만 배치처리를 할경우 계산을 위해 편향벡터를 배치크기만큼 반복한 행이 만들어져 행렬이 구성된다.\n",
        "                                       # 이 경우 각열을 모두 더한 값이 역전파의 결과로 반환된다.(수학적인 증명은 아님.) 자세한 설명은 노트참고\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "Lkauop5_uQC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "softmax 함수"
      ],
      "metadata": {
        "id": "OcXmsz5cA9TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    if x.dim == 2:   # x가 행렬일 경우, 즉 배치처리를 해서 각 행이 확률벡터인 메트릭스를 입력받은 경우.\n",
        "        x = x.T # 각 행이 확률벡터인 초기 메트릭스에서 각 열이 확률벡터인 메트릭스로 전치 시킨다.\n",
        "        x = x - np.max(x, axis = 0) # np.max(x, axis = 0)는 각 열에 대한 최댓값을 저장한 리스트(벡터)를 반환 한다. 그리고 x에 대한 - 연산은 각 열의 확률벡터에 각 열의 최댓값을 빼주는 연산이다.(밑의 오버플로우 방지를 위한 최댓값 빼기와 같음.)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis = 0) # 위와 같은 행렬과 벡터의 연산 원리.( 밑의 예제 참고.)\n",
        "        return y.T\n",
        "\n",
        "    x = x - np.max(x) # 오버플로를 방지하기위해 작성. 노트참고. , vector에 scalar를 빼면 numpy에서 알아서 원소별로 연산을 한다.\n",
        "    return np.exp(x) / np.sum(np.exp(x))  # normalize"
      ],
      "metadata": {
        "id": "XerKaN4OABdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross entropy 함수"
      ],
      "metadata": {
        "id": "Z8n7QNACBL8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corss_entropy_error(y, t):\n",
        "    if y.ndim == 1: # y가 벡터인 경우, 배치처리를 안 한 경우\n",
        "        t = t.reshape(1, t.size) # 10차원 벡터를 행렬로 변환.(개념상.)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    if t.size == y.size: # 라벨이 원-핫 인코딩이 돼어 있다면, 그러니까 입력 값이 10차원 벡터라면, size함수는 메트릭스의 원소갯수를 반환한다.\n",
        "        t = t.argmax(axis=1) # 원-핫 인코딩 이전으로 되돌리기 위해 작성.\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size # 설명1, 확률벡터로 이루어진 행렬에서 알맞은 인덱스를 얻기위한 과정."
      ],
      "metadata": {
        "id": "OfAjtGY4BOwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid층의 순전파와 역전파\n",
        "\n",
        "sigmoid함수는 고전적인 미분값계산시 미분계산이 간단한 덧셈, 곱셈 문제로 바뀐다. 또한 계산그래프로도 이러한 결과를 도출할 수 있다.(노트 참고)\n",
        "\n",
        "sigmoid함수의 역전파는\n",
        "\n",
        "$\\frac{\\partial L}{\\partial y}y(1-y)$"
      ],
      "metadata": {
        "id": "LWKX7iWF1JiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = 1 / (1 + np.exp(-x))\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "        return dx"
      ],
      "metadata": {
        "id": "MJ6d5dtj1Q9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RELU층의 순전파와 역전파\n",
        "\n",
        "RELU함수는 Deep Nueral Network에서 발생하는 sigmoid함수의 vanishing gradient문제를 해결할 수 있다.(노트 참고)"
      ],
      "metadata": {
        "id": "sHERwU8D-FBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0) # self.mask는 0보다 크면 false 0보다 작으면 true인 리스트를 반환한다.\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0 # 설명1\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0 # 위의 설명1을 참조. 주의할점은 흘러들어온 미분값의 부호에 의해 1이나 0을 곱하는것이 정해지는게 아니라 위의 x값을 기준으로 gradient를 살리거나 죽이게 된다.\n",
        "        dx = dout\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "xGpGguZZ-NZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트"
      ],
      "metadata": {
        "id": "hdcE3foqD_-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BTS = Relu()\n",
        "\n",
        "print(BTS.forward(np.array([1,-2,3,-4])))\n",
        "print(BTS.mask)\n",
        "print(BTS.backward(np.array([1,2,-3,-4])))"
      ],
      "metadata": {
        "id": "SOZnEy3pCufW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "설명"
      ],
      "metadata": {
        "id": "uaD0p7l9D7pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 설명1\n",
        "test = np.array([1,2,3,4,])\n",
        "test1 = np.array([True, False, False, False])\n",
        "test[test1] = 0\n",
        "test"
      ],
      "metadata": {
        "id": "jGKNp6JjBCXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax with Loss층의 순전파와 역전파\n",
        "softmax층과 loss층은 특이하게도 따로 미분하는 것 보다 합성합수로 미분하는 것이 더 간단한 식을 도출할 수 있다. 고전적인 미분이나 계산 graph를 이용한 역전파로 구할 수 있는 미분계수는 뺄셈연산으로 간단하게 변한다.\n",
        "\n",
        "$\\frac{\\partial L}{\\partial a} = y-t$"
      ],
      "metadata": {
        "id": "eDDKDbb_-cpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None #손실함수\n",
        "        self.y = None # softmax의 출력(확률 벡터)\n",
        "        self.t = None # 정답 레이블(one-hot encoding 형태)\n",
        "\n",
        "    def forward(self, x,  t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = corss_entropy_error(self.y, self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout = 1): # 역전파의 시작은 1 이다.\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩이 돼어 있는 경우.\n",
        "            dx = (self.y - self.t) / batch_size # 손실함수의 정의 값은 각각의 손실함수값의 평균이므로 배치사이즈로 나누어 준다.\n",
        "\n",
        "        else: # 원-핫 이코딩이 돼어 있지 않은 경우.\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1 # 도출된 확률벡터는 배치처리로 묶여있다는 것을 생각해보면 위와 같은 결과를 도출함.\n",
        "            dx = dx / batch_size\n",
        "\n",
        "            return dx"
      ],
      "metadata": {
        "id": "VMJIzzrL_2d-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}