{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "5lksxa6OBhv9",
        "R5c8FDJ8uRWY",
        "LWKX7iWF1JiK",
        "sHERwU8D-FBe",
        "eDDKDbb_-cpY",
        "q-w8goGksTDs",
        "3tSWIHzJD6eC",
        "esAW-52wOTG9"
      ],
      "authorship_tag": "ABX9TyNbPgqMpCSSJKvXcaEcoen2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwoong2/deeplearning/blob/main/%EA%B0%81%EC%B8%B5_%EC%88%9C%EC%A0%84%ED%8C%8C%2C_%EC%97%AD%EC%A0%84%ED%8C%8C_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nZj863xrfX0"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 필요한 함수들"
      ],
      "metadata": {
        "id": "5lksxa6OBhv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
        "    filter_h : 필터의 높이\n",
        "    filter_w : 필터의 너비\n",
        "    stride : 스트라이드\n",
        "    pad : 패딩\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    col : 2차원 배열\n",
        "    \"\"\"\n",
        "    N, C, H, W = input_data.shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "\n",
        "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
        "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        "\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
        "    return col\n",
        "\n",
        "\n",
        "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    col : 2차원 배열(입력 데이터)\n",
        "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
        "    filter_h : 필터의 높이\n",
        "    filter_w : 필터의 너비\n",
        "    stride : 스트라이드\n",
        "    pad : 패딩\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    img : 변환된 이미지들\n",
        "    \"\"\"\n",
        "    N, C, H, W = input_shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
        "\n",
        "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
        "\n",
        "    return img[:, :, pad:H + pad, pad:W + pad]"
      ],
      "metadata": {
        "id": "rRTwemZZ82i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Affine층의 순전파와 역전파"
      ],
      "metadata": {
        "id": "R5c8FDJ8uRWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "범용적인 affine 층 구현"
      ],
      "metadata": {
        "id": "EtMPqWzjuYTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4차원 텐서를 염두해둔 코드이기 떄문에 다음 학기때완전히 이해가능\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W # 가중치 행렬\n",
        "        self.b = b # bias 벡터\n",
        "\n",
        "        # 입력된 data 초기화\n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 bias 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1) # 4차원 텐서를 행렬로 변환. -1을 입력하면 reshape 가능한 숫자를 알아서 대입한다.\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b # affine 변환. bias의 경우 배치처리를 할경우 행렬뎃섬에서 shape이 맞지 않는데 numpy에서 자동으로 벡터를 복사해 각 열에 더하게 된다.\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout): # dout:흘러들어온 미분\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0) # 행렬의 경우 axis 0: 행, 1: 열. 텐서의 경우 axis 0: 각 행렬, 1: 각 행렬의 행, 2: 각 행렬의 열\n",
        "\n",
        "        dx =dx.reshape(*self.original_x_shape) # 입력데이터\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "eAy-DJY9r0cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1,1]])\n",
        "\n",
        "W = np.array([[1,2,3],[4,5,6]])\n",
        "\n",
        "b = np.array([7,8,9])\n",
        "\n",
        "test = Affine(W,b)"
      ],
      "metadata": {
        "id": "_ARWvQCLyGdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 순전파 테스트\n",
        "test.forward(x)"
      ],
      "metadata": {
        "id": "MXrUjhR9yd8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 역전파 테스트\n",
        "print(test.backward(np.array([[2,1,-1]])))\n",
        "print(test.dW)\n",
        "print(test.db)"
      ],
      "metadata": {
        "id": "sRj5e7KMyiN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 배기처리 테스트\n",
        "y = np.array([[1,1],[2,3]])\n",
        "\n",
        "# 순전파 테스트\n",
        "print(test.forward(y))\n",
        "\n",
        "# 역전파 테스트\n",
        "print(test.backward(np.array([[2,1,-1],[1,1,1]])))\n",
        "print(test.dW)\n",
        "print(test.db)"
      ],
      "metadata": {
        "id": "J-An3fSz4hpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "간단한 affine층 구현"
      ],
      "metadata": {
        "id": "7YmYWwUAuck5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine_t:\n",
        "    def __init__(self, W, b): # W:가중치 matrix, b:bias\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x # x:data\n",
        "        out = np.dot(self.x, self.W) + self.b # affine 변환\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout): # dout:흘러들어온 미분\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0) # 덧셈노드의 역전파는 원래 흘러들어온 값이 그대로 통과하지만 배치처리를 할경우 계산을 위해 편향벡터를 배치크기만큼 반복한 행이 만들어져 행렬이 구성된다.\n",
        "                                       # 이 경우 각열을 모두 더한 값이 역전파의 결과로 반환된다.(수학적인 증명은 아님.) 자세한 설명은 노트참고\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "Lkauop5_uQC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "softmax 함수"
      ],
      "metadata": {
        "id": "OcXmsz5cA9TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    if x.dim == 2:   # x가 행렬일 경우, 즉 배치처리를 해서 각 행이 확률벡터인 메트릭스를 입력받은 경우.\n",
        "        x = x.T # 각 행이 확률벡터인 초기 메트릭스에서 각 열이 확률벡터인 메트릭스로 전치 시킨다.\n",
        "        x = x - np.max(x, axis = 0) # np.max(x, axis = 0)는 각 열에 대한 최댓값을 저장한 리스트(벡터)를 반환 한다. 그리고 x에 대한 - 연산은 각 열의 확률벡터에 각 열의 최댓값을 빼주는 연산이다.(밑의 오버플로우 방지를 위한 최댓값 빼기와 같음.)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis = 0) # 위와 같은 행렬과 벡터의 연산 원리.( 밑의 예제 참고.)\n",
        "        return y.T\n",
        "\n",
        "    x = x - np.max(x) # 오버플로를 방지하기위해 작성. 노트참고. , vector에 scalar를 빼면 numpy에서 알아서 원소별로 연산을 한다.\n",
        "    return np.exp(x) / np.sum(np.exp(x))  # normalize"
      ],
      "metadata": {
        "id": "XerKaN4OABdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross entropy 함수"
      ],
      "metadata": {
        "id": "Z8n7QNACBL8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corss_entropy_error(y, t):\n",
        "    if y.ndim == 1: # y가 벡터인 경우, 배치처리를 안 한 경우\n",
        "        t = t.reshape(1, t.size) # 10차원 벡터를 행렬로 변환.(개념상.)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    if t.size == y.size: # 라벨이 원-핫 인코딩이 돼어 있다면, 그러니까 입력 값이 10차원 벡터라면, size함수는 메트릭스의 원소갯수를 반환한다.\n",
        "        t = t.argmax(axis=1) # 원-핫 인코딩 이전으로 되돌리기 위해 작성.\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size # 설명1, 확률벡터로 이루어진 행렬에서 알맞은 인덱스를 얻기위한 과정."
      ],
      "metadata": {
        "id": "OfAjtGY4BOwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid층의 순전파와 역전파\n",
        "\n",
        "sigmoid함수는 고전적인 미분값계산시 미분계산이 간단한 덧셈, 곱셈 문제로 바뀐다. 또한 계산그래프로도 이러한 결과를 도출할 수 있다.(노트 참고)\n",
        "\n",
        "sigmoid함수의 역전파는\n",
        "\n",
        "$\\frac{\\partial L}{\\partial y}y(1-y)$"
      ],
      "metadata": {
        "id": "LWKX7iWF1JiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = 1 / (1 + np.exp(-x))\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "        return dx"
      ],
      "metadata": {
        "id": "MJ6d5dtj1Q9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RELU층의 순전파와 역전파\n",
        "\n",
        "RELU함수는 Deep Nueral Network에서 발생하는 sigmoid함수의 vanishing gradient문제를 해결할 수 있다.(노트 참고)"
      ],
      "metadata": {
        "id": "sHERwU8D-FBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0) # self.mask는 0보다 크면 false 0보다 작으면 true인 리스트를 반환한다.\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0 # 설명1\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0 # 위의 설명1을 참조. 주의할점은 흘러들어온 미분값의 부호에 의해 1이나 0을 곱하는것이 정해지는게 아니라 위의 x값을 기준으로 gradient를 살리거나 죽이게 된다.\n",
        "        dx = dout\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "xGpGguZZ-NZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트"
      ],
      "metadata": {
        "id": "hdcE3foqD_-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BTS = Relu()\n",
        "\n",
        "print(BTS.forward(np.array([1,-2,3,-4])))\n",
        "print(BTS.mask)\n",
        "print(BTS.backward(np.array([1,2,-3,-4])))"
      ],
      "metadata": {
        "id": "SOZnEy3pCufW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "설명"
      ],
      "metadata": {
        "id": "uaD0p7l9D7pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 설명1\n",
        "test = np.array([1,2,3,4,])\n",
        "test1 = np.array([True, False, False, False])\n",
        "test[test1] = 0\n",
        "test"
      ],
      "metadata": {
        "id": "jGKNp6JjBCXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax with Loss층의 순전파와 역전파\n",
        "softmax층과 loss층은 특이하게도 따로 미분하는 것 보다 합성합수로 미분하는 것이 더 간단한 식을 도출할 수 있다. 고전적인 미분이나 계산 graph를 이용한 역전파로 구할 수 있는 미분계수는 뺄셈연산으로 간단하게 변한다.\n",
        "\n",
        "$\\frac{\\partial L}{\\partial a} = y-t$"
      ],
      "metadata": {
        "id": "eDDKDbb_-cpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None #손실함수\n",
        "        self.y = None # softmax의 출력(확률 벡터)\n",
        "        self.t = None # 정답 레이블(one-hot encoding 형태)\n",
        "\n",
        "    def forward(self, x,  t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = corss_entropy_error(self.y, self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout = 1): # 역전파의 시작은 1 이다.\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩이 돼어 있는 경우.\n",
        "            dx = (self.y - self.t) / batch_size # 손실함수의 정의 값은 각각의 손실함수값의 평균이므로 배치사이즈로 나누어 준다.\n",
        "\n",
        "        else: # 원-핫 이코딩이 돼어 있지 않은 경우.\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1 # 도출된 확률벡터는 배치처리로 묶여있다는 것을 생각해보면 위와 같은 결과를 도출함.\n",
        "            dx = dx / batch_size\n",
        "\n",
        "            return dx"
      ],
      "metadata": {
        "id": "VMJIzzrL_2d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BatchNormalization"
      ],
      "metadata": {
        "id": "q-w8goGksTDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BatchNormalization은 각 행이 데이터인 배치 행렬의 각 열(data의 각 feature)을 평균이 0이고 표준편차가 1인 정규분포로 변환한 후 머신이 최적의 scailing:$\\gamma$ 와 shift:$\\beta$를 찾아 적용하게 한다. 최종적으로 배치처리된 data의 각 featur의 표준편차가 $\\gamma$ 평균이 $\\beta$인 분포를 가지게 된다."
      ],
      "metadata": {
        "id": "ZGaaZlTFsY6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchNormalization:\n",
        "\n",
        "    def __init__(self, gamma, beta, momentum = 0.9, running_mean = None, running_var = None): # gamma와 beta는 머신이 학습해 최적값을 찾지만 초기값을 설정해 줘야 한다.\n",
        "                                                                                              # running_mean = None, running_var = None : 학습중엔 각 배치행렬(data 묶음)의 열(feature)을 사용해\n",
        "                                                                                              # 평균과, 분산을 구해 사용하지만 학습이 끝난후엔 학습하는 동안의 전체 훈련용 data의 평균과 분산(비슷한 값?)\n",
        "                                                                                              # 을 사용해 normalizetion 한다.\n",
        "        self.gamma = gamma\n",
        "        self.beta = beta\n",
        "        self.momentum = momentum\n",
        "        self.input_shape = None # 합성곱 계층은 4차원, 완전연결 계층은 2차원\n",
        "\n",
        "        # test용 평균, 분산\n",
        "        self.running_mean = running_mean\n",
        "        self.running_var = running_var\n",
        "\n",
        "        # backward 시에 사용할 중간 데이터\n",
        "        self.batch_size = None\n",
        "        self.xc = None\n",
        "        self.std = None\n",
        "        self.dgamma = None\n",
        "        self.dbeta = None\n",
        "\n",
        "    def forward(self, x, train_flg = True): # x는 입력 data, train_flag : 위의 주석처럼 훈련시와 test시의 순전파방식이 다르기 때문에 훈련시 train_flg를 True로 지정해 이를 구분한다.\n",
        "        self.input_shape = x.shape\n",
        "        if x.ndim != 2: # 행렬이 아니면. 지금까지는 data를 flatten한후 배치처리 했기때문에 인풋이 행렬이었지만, cnn등에서는 data를 faltten시키지 않기때문에 행렬이 아니라 텐서가 입력된다.\n",
        "                        # N은 배치사이즈, C는 채널, H는 세로해상도, W는 가로해상도\n",
        "            N, C, H, W = x.shape\n",
        "            x = x.reshape(N, -1)\n",
        "\n",
        "        out = self.__forward(x, train_flg)\n",
        "\n",
        "        return out.reshape(*self.input_shape) # shape을 원래대로 복원한다. *는 ()를 없에준다.\n",
        "\n",
        "    def __forward(self, x, train_flg):\n",
        "        if self.running_mean is None:\n",
        "            N, D = x.shape\n",
        "            self.running_mean = np.zeros(D)\n",
        "            self.running_var = np.zeros(D)\n",
        "\n",
        "        if train_flg: # 훈련시.\n",
        "            mu = x.mean(axis = 0) # 열의 평균\n",
        "            xc = x - mu # 각 열의 평균이 0이 됨.\n",
        "            var = np.mean(xc**2, axis = 0) # 분산\n",
        "            std = np.sqrt(var + 10e-7) # 표준편차\n",
        "            xn = xc / std # 각 열의 표준편차가 1이됨.\n",
        "\n",
        "            self.batch_size = x.shape[0]\n",
        "            self.xc = xc\n",
        "            self.xn = xn\n",
        "            self.std = std\n",
        "            self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * mu # RMSProp에서 사용한 기법처럼 평균벡터를 계속해서 내분하는 과정. 결과적으로 계속해서 바뀌는 배치묶음의 평균 추세를 따라간다.\n",
        "            self.running_var = self.momentum * self.running_var + (1 - self.momentum) * var\n",
        "\n",
        "        else: # train_flg가 false일 경우 즉, test시에는 running_mean와 running_var을 사용한다.\n",
        "            xc = x - self.running_mean\n",
        "            xn = xc / ((np.sqrt(self.running_var + 10e-7)))\n",
        "\n",
        "        out = self.gamma * xn + self.beta # gamma를 곱해 표준편차를 조정하고 beta를 더해 평균을 조정한다.\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        if dout.ndim != 2:\n",
        "            N, C, H, W = dout.shape\n",
        "            dout = dout.reshape(N, -1)\n",
        "\n",
        "        dx = self.__backward(dout)\n",
        "\n",
        "        dx = dx.reshape(*self.input_shape)\n",
        "\n",
        "        return dx\n",
        "\n",
        "    def __backward(self, dout):\n",
        "        dbeta = dout.sum(axis = 0) # 덧셈노드를  브로드캐스팅(repeat 노드를 통과)방식으로 계산하기때문에 덧셈노드의 역전파뿐 아니라 repeat노드의 역전파인 sum노드를 추가해야한다.\n",
        "        dgamma = np.sum(self.xn * dout, axis = 0) # *는 adamard  product임.\n",
        "        dxn = self.gamma * dout\n",
        "        dxc = dxn / self.std\n",
        "        dstd = -np.sum((dxn * self.xc) / (self.std * self.std), axis = 0)\n",
        "        dvar = 0.5 * dstd / self.std\n",
        "        dxc += (2.0 / self.batch_size) * self.xc * dvar\n",
        "        dmu = np.sum(dxc, axis = 0)\n",
        "        dx = dxc - dmu / self.batch_size\n",
        "\n",
        "        self.dgamma = dgamma\n",
        "        self.dbeta = dbeta\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "gMDrwgQFsZNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test, 검산"
      ],
      "metadata": {
        "id": "K_e05k_OChWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = np.array([np.sqrt(2), 2 * np.sqrt(2), np.sqrt(30)])\n",
        "beta = np.array([2, 4, 5])\n",
        "\n",
        "ico = BatchNormalization(gamma, beta)\n",
        "\n",
        "x = np.array([[1, -1, 1], [2, -2, 1], [3, -3, 2], [4, -4, 2], [5, -5, 4]])"
      ],
      "metadata": {
        "id": "Tmk5kjqmCj5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ico.forward(x)"
      ],
      "metadata": {
        "id": "sOZlX5siDOxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dout = np.array([[1, -1, 4], [-1, 1, -4], [1, -1, 4], [-1, 1, -4], [1, -1 ,4]])"
      ],
      "metadata": {
        "id": "VyboFIDPwpqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ico.backward(dout)"
      ],
      "metadata": {
        "id": "LHRmvOv6xYhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ico.dbeta"
      ],
      "metadata": {
        "id": "fo7-REs-yV7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ico.dgamma"
      ],
      "metadata": {
        "id": "BcQZKP2gya-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout"
      ],
      "metadata": {
        "id": "3tSWIHzJD6eC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "뉴런을 무작위로 선택해 삭제하여 신호전달을 차단한다."
      ],
      "metadata": {
        "id": "bJnJfMNJD_7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dropout:\n",
        "\n",
        "    def __init__(self, dropout_ratio = 0.5):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x, train_flg = True): # Dropout층은 훈련시에만 적용함.\n",
        "        if train_flg:\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio # .rand는 0부터 1까지의 균등분포로 랜덤값을 생성함. self.mask는 true, false로 이루어진 행렬이 됨.\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio) # 신호량을 맞추기위해 리스케일링. 이해안감.\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask # 신호를 죽인부분은 미분도 죽임."
      ],
      "metadata": {
        "id": "HfxOFiiNEGhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution"
      ],
      "metadata": {
        "id": "esAW-52wOTG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution:\n",
        "    def __init__(self, W, b, stride=1, pad=0):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        # 중간 데이터（backward 시 사용）\n",
        "        self.x = None\n",
        "        self.col = None\n",
        "        self.col_W = None\n",
        "\n",
        "        # 가중치와 편향 매개변수의 기울기\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
        "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
        "\n",
        "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
        "        col_W = self.W.reshape(FN, -1).T\n",
        "\n",
        "        out = np.dot(col, col_W) + self.b\n",
        "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        "\n",
        "        self.x = x\n",
        "        self.col = col\n",
        "        self.col_W = col_W\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout): # convolution층은 im2col -> affine -> reshape층으로 세분화해 생각할 수 있다.\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "\n",
        "        # reshape층의 역전파 재배열의 역전파는 역재배열이다. 최종적으로 행렬이 반환된다.\n",
        "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
        "\n",
        "        # affine층의 역전파. (가중치에 대한 미분)\n",
        "        self.db = np.sum(dout, axis=0) # 각 열을 합하는 이유는 파이썬의 브로드캐스팅에 의해 편향을 더할때 리피트노드가 숨어있기 때문이다. (리피트의 역전파는 sum)\n",
        "        self.dW = np.dot(self.col.T, dout)\n",
        "\n",
        "        # 필터를 가중치행렬로 만드는 과정의 역전파.\n",
        "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
        "\n",
        "        # affine층 역전파. (데이터에 대한 미분)\n",
        "        dcol = np.dot(dout, self.col_W.T)\n",
        "        # im2col층의 역전파\n",
        "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "sNi8QJ30OSL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max Pooling"
      ],
      "metadata": {
        "id": "qU2lzaIyDqMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max pooling층은 개념은 간단하지만 연산속도등의 이유로 실제 구현시에는 im2col을 사용해 연산하므로 코드가 복잡해진다.\n",
        "\n",
        "1. 데이터에 im2col을 취한다.\n",
        "2. 열이 PH*PW가 되도록 reshape을 한다.\n",
        "3. 각 행에 최대를 취한다.\n",
        "4. N*OH*OW*C로 reshape을 한다.\n",
        "5. transpose(0,3,1,2)를 취한다."
      ],
      "metadata": {
        "id": "EpdHpGnqEImY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pooling:\n",
        "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
        "        self.pool_h = pool_h\n",
        "        self.pool_w = pool_w\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "        self.x = None\n",
        "        self.arg_max = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
        "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
        "\n",
        "        # im2col\n",
        "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "        # 열이 PH*PW가 되도록 reshpae\n",
        "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
        "        # 역전파시 필요한 과정\n",
        "        arg_max = np.argmax(col, axis=1)\n",
        "        # 각행의 최대값을 추출\n",
        "        out = np.max(col, axis=1)\n",
        "        # NOHOW*C로 reshape -> transpose(0,3,1,2)를 취한다.\n",
        "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        "\n",
        "        self.x = x\n",
        "        self.arg_max = arg_max\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout = dout.transpose(0, 2, 3, 1)\n",
        "\n",
        "        pool_size = self.pool_h * self.pool_w\n",
        "        dmax = np.zeros((dout.size, pool_size))\n",
        "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
        "        dmax = dmax.reshape(dout.shape + (pool_size,))\n",
        "\n",
        "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
        "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "\n",
        "        return dx"
      ],
      "metadata": {
        "id": "lWS6Ilk1DvEC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}